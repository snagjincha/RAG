{"train_config": {"model_dtype": "cast_bf16", "batch_size": 16, "eval_batch_size": 16, "gradient_accumulation_steps": 2, "num_train_epochs": 2, "max_steps": null, "optimizer_type": "adamw", "learning_rate": 0.0003, "weight_decay": 0.01, "warmup_steps": 1000, "max_grad_norm": 1.0, "lr_scheduler_type": "cosine", "metric_for_best_model": "ppl", "metric_greater_is_better": false, "eval_interval": 2500, "logging_interval": 10, "save_total_limit": 3}}
